% !TeX encoding = UTF-8
% !TeX program = pdflatex

%----------------------------------------------------------------------------------------
%    PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}   % for \textcolor
\usepackage{relsize}

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
%\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text


\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\lstnewenvironment{pycode}[1][]{
    \lstset{
        language=python,
        numbers=left,
        stepnumber=1,
        breaklines=true,
        basicstyle=\linespread{1.0}\ttfamily,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        commentstyle=\color{OliveGreen}\ttfamily,
        morecomment=[l][\color{magenta}]{\#}
        columns=fullflexible,
        otherkeywords={self,as},
        postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
        escapeinside={(*@}{@*)},
        showstringspaces=false,
    }
    \lstdefinestyle{nonumbers}
    {numbers=none}
}{}

\lstnewenvironment{ccode}[1][]{
    \lstset{
        language=C,
        numbers=left,
        stepnumber=1,
        breaklines=true,
        basicstyle=\linespread{1.0}\ttfamily,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        commentstyle=\color{OliveGreen}\ttfamily,
        morecomment=[l][\color{magenta}]{\#}
        columns=fullflexible,
        otherkeywords={},
        postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
        escapeinside={(*@}{@*)},
        showstringspaces=false,
    }
    \lstdefinestyle{nonumbers}
    {numbers=none}
}{}

\lstdefinelanguage{pseudocode}{
    alsodigit = {-},
    keywords = {algorithm,new,if,else,while,for,foreach,to,in,return,true,false,and,or,not,error,is,skip}
}


\lstnewenvironment{pseudo}[1][]{
    \lstset{
        language=pseudocode,
        mathescape=true,
        numbers=left,
        stepnumber=1,
        breaklines=true,
        basicstyle=\linespread{1.0},
        keywordstyle=\bfseries,
        stringstyle=\color{red}\ttfamily,
        columns=fullflexible,
        otherkeywords={},
        postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
        showstringspaces=false,
    }
    \lstdefinestyle{nonumbers}
    {numbers=none}
}{}


\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother


%----------------------------------------------------------------------------------------
%    TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{    
\normalfont \normalsize 
\textsc{Sapienza University of Rome} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Algorithm Design First Homework \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Andrea Fioraldi 1692419} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

\section*{Exercise 1}

This problem can be viewed as a simplification of the K-center clustering problem. This problem has an approximate solution, a greedy 2-approximation algorithm. We used this simplification and we also proved that this approach is optimal for our problem.

$C$ is the subset of $X$ that contains the centers. The algorithm is the following:

\begin{enumerate}
    \item Pick an arbitrary point $c_1$ and insert in into $C$;
    \item Pick the point $x$ with the highest distance from the nearest center $c_i$;
    \item Insert $x$ into $C$;
    \item Continue from 2 until $|C| < k$;
\end{enumerate}

In pseudocode:

\begin{pseudo}
algorithm $k\_centers(G, k)$
    $c := random\_select(G.V)$
    $G.V = G.V \setminus \{c\}$
    $C := \{c\}$
    $distances :=$ new $Array(|G.V|)$
    $distances_i = +\infty$ $\forall i = 0 ... |G.V|$
    while $|C| < k$
        $new\_c := none$
        $max\_dist := -\infty$
        foreach $v \in G.V$
            $d := min(distances_v, G.weigth(c, v))$
            if $max\_dist < d$
                $max\_dist = d$
                $new\_c = c$
        $c = new\_c$
        $G.V = G.V \setminus \{c\}$
        $C = C \cup \{c\}$
    return $C$
\end{pseudo}


The \verb|distances| list is an optimization used to avoid to compute the distance between a node $x \in X$ and all centers in all of the iterations. \verb|distances| keeps track of the distance of each node from its nearest center. In each iteration only a center $c_i$ is added, so the distance from the nearest center can remain the same or be updated to $d(x, c_i)$.

This approximation cost is $O(n*k)$ because in each iteration all nodes are processed and there are $k$ iterations. 

To compute the permutation requested by the exercise we run the algorithm with $k = n$, where $n = |X|$.
This is possible thanks to the fact that in this greedy algorithm the iteration $i$ is not dependent on the presence of an iteration $i+1$ so computing $k\_center(G, k)$ is equivalent to $slice(k\_center(G, n), 1, k)$ (compute using $k=n$ and after take only the first $k$ elements of the output).

Now, we prove that this greedy algorithm is optimal for our problem thanks to the fact that the distances can be only 0, 1 or 3.

For the K-center this algorithm is a 2-approximation, so the approximated minimized maximum of the distances of each point in $X$ to the closest center is at most the twice of the optimal one.
We will notate the approximated with $r_A$ and the optimal with $r_O$.

Regards our problem both $r_A$ and $r_O$ can be 0 only if $|C| = |X|$, so in this case they are equal.
There are other 4 cases to consider:

\begin{itemize}
    \item $r_A = 1 \land r_O = 3$ is not possible because an approximation cannot perform better than the optimal algorithm \footnote{A p-approximation $f$, as described in \cite{app}, perform $OPT$ $\leq f \leq$ $p*OPT$}.
    \item $r_A = 3 \land r_O = 1$ is not possible because $r_A > 2*r_O$;
    \item $r_A = 3 \land r_O = 3$ is optimal;
    \item $r_A = 1 \land r_O = 1$ is optimal;
\end{itemize}

Follows that in our problem $r_A$ must be equal to $r_O$, so our algorithm is optimal and not an approximation.

\bigskip
\section*{Exercise 2}

The problem can be represented with a bipartite graph $G(L \cup R, E)$.
The nodes of the class $L$ represents the avenues and the nodes of the class $R$ the streets.
The edges in $E$ are the checkpoints.
Using a reversed perspective, the adjacency matrix of such graph is the grid of avenues and streets with the edges represented by checkpoints.

A vertex cover of such graph (the set of nodes so that each edge has at least one endpoint in the set) represents a set of streets and avenues that can cover all checkpoints.
A minimum vertex cover is the set of streets and avenues that solves our problem.

Generally, a minimum vertex cover is a hard problem but with bipartite graphs, we can solve it in polynomial time thanks to the KÅ‘nig's theorem.

According to \cite{konig_wiki}, the statement is the following:

\bigskip
\textit{In any bipartite graph, the number of edges in a maximum matching equals the number of vertices in a minimum vertex cover.}
\bigskip

Its proof offers a method to retrieve the minimum vertex cover from the maximum bipartite matching.

Adding a source node $s$ to one side and a sink node $t$ to the other we create a flow network based on the bipartite graph:

$G'(L \cup R \cup \{s, t\}, c, s, t)$

All edges capacities are $0$ except the following:

\begin{itemize}
    \item $c(s, l) = 1$  $ \forall l \in L$;
    \item $c(r, t) = 1$  $ \forall r \in R$;
    \item $c(e) = \infty$  $ \forall e \in E$;
\end{itemize}

The amount of flow for each edge can be 0 or 1.
For each flow the subset of $E$ with $f(e) = 1$ is a matching of cardinality equal to the value of the flow.
So a maxflow value is equal to the cardinality of a maximum matching $M$.
Let $(S, T)$ the mincut associated with the computed maxflow using Ford-Fulkerson.

Consider the set $C = (L \cap T) \cup (R \cap S)$. We want to prove that $C$ is a vertex cover and $|C| = |M|$.

Firstly, assume that $C$ is not a vertex cover. So we have an edge $e \in E$ with endpoint in $L \cap S$ and $R \cap T$ with capacity $c(e) = \infty$ (the capacity is always $\infty$ in the original edges). This is absurd because an infinite capacity edge cannot be in a minimum cutset (it has one endpoint in $S$ and the other in $T$), so all edges have endpoints in $(L \cap T) \cup (R \cap S) = C$ and $C$ is a vertex cover.

Secondly, we have that:
\begin{itemize}
\item thanks to the maxflow mincut theorem the cardinality of $M$ is equal to the capacity of $(S, T)$;
\item the capacity of $(S, T)$ is equal to the number of edges in the cutset that is composed only by edges from $s$ to $T$ and from $S$ to $t$ (otherwise they would have an infinite capacity);
\item such edges are associted to $(L \cap T)$ and $(R \cap S)$, so $|M| = cap(S, T) = |(L \cap T)| + |(R \cap S)| = |C|$.
\end{itemize}

So a minimum vertex cover can be computed using the Ford-Fulkerson method and is $(L \cap T) \cup (R \cap S)$.

We propose a solution that makes use of a variant of Ford-Fulkerson that guarantee termination, the Edmonds-Karp algorithm, which has cost $O(|V|*|E|^2)$, and then of two DFS in the residual graph in order to compute $L \cap T$ and $R \cap S$.
So the final cost is $O(|V|*|E|^2+2*|V|+2*|E|) = O(|V|*|E|^2)$.

\bigskip
\section*{Exercise 3}

We represents our problem using a undirected unweigthed graph. Each node of the graph is a friend and an edge $(v,u)$ is present if $w(v,u) = 1$.
The goal is to find the subset of nodes $I$ that maximize $\frac{1}{|I|} \Sigma_{x,y \in I} w(x, y)$ respecting the constraint $|I \cap M| = |I \cap F|$.
In other words, it is the densest subgraph that has an equal number of M and F nodes.

\subsection*{Certifier}

In order to verify an input $s$ we create an efficent certifier $CERT(s, t)$:

\begin{itemize}
    \item if $s \cap M \neq s \cap F$ return no;
    \item let $d_s = \frac{1}{|s|} \Sigma_{x,y \in s} w(x, y)$;
    \item let $d_t = \frac{1}{|t|} \Sigma_{x,y \in t} w(x, y)$;
    \item return yes if $d_s \geq d_t$ else return no;
\end{itemize}

$CERT$ runs in polynomial time, precisely $O(|s|+|t|)$. This certifer can be used in a brute-force over all possibles set of friends $t$ with $|t| \leq |s|$. If all attempts returs yes, $s$ is the solution.

\subsection*{Reduction}

Given our problem $X$ and the clique decision problem $Y$, we will prove that $Y \leq_p X$.
The clique decision problem takes as input an undirected unweighted graph $G(V, E)$ and a number $k$ and it says yes if the graph contains a clique of $k$ nodes.
$Y$ is NP-complete.

To transform an input for $Y$ to an input for $X$ we create a graph $G'(M, F, E')$ copying the nodes of graph $G$ into $M$ and the edges into $E'$. Then we create $k$ nodes in $F$ and we connect them in a clique adding edges to $E'$.

Note that an output of $X_{ALG}$ contains a clique of F-nodes because a subgraph of a clique is a clique. So if the output contains $t$ M-nodes then it contains also a clique of F-nodes of size $t$.

Assume that exists a clique of size $k$ composed by $M$-nodes and that $X_{ALG}$ returns an output with less $M$-nodes than $k$ or with $k$ $M$-nodes but that is not a clique.
This is not possible because the densest graph of $k$ nodes is a clique by definition and a clique of $k$ nodes is denser than every clique with fewer nodes (the density of a clique $\frac{x(x-1)/2}{x}$ is a monotonous growing succession).

Assume that exists a clique of size $k$ composed by nodes of $M$ and that $X_{ALG}$ returns an output with more $M$-nodes than $k$.
This is not possible because we have at most $k$ $F$-nodes and so it violates $|I \cap M| = |I \cap F|$.

Assume that exists a clique of size $k$ composed by nodes of $M$ and that $X_{ALG}$ returns it as part of the output.
Deleting the F-nodes clique from the output give us the M-nodes clique.
Another result is not possible because it implies that there are edges from $M$ to $F$ and this violates our construction of the graph.

So with $X_{ALG}$, our black box solver, we can solve an instance of $Y$ checking if the $M$-nodes in the output forms a clique of size $k$.

\bigskip
\section*{Exercise 4}

The related code is in the Appendix.

\subsection*{Part 1}

Assumptions:
\begin{itemize}
    \item at the beginning we do not have a hired worker;
    \item at the end if we have and hired worker we do not have to fire him;
\end{itemize}

We never use a freelance when we have a hired worker because we must pay a hired worker also when is not working, so if we have a hired worker is always convenient to use him.

In addition, it is never covenient to use a freelance if we decide to use an hired worker because he can process all the works at time $t$.
So the choice is between use an hired worker or use $k$ freelances when we have $k$ works at time $t$. This is equivalent to consider the cost of using the $k$ freelences to the cost of using a freelence with cost equal to the sum of all costs of the $k$ freelances and then consider only a work for each time instant.

From now on we consider that each time instant can have 0 or 1 tasks exploiting the previous consideration.

We denote as $OPT(x, h)$ the minimum cost of execution of the task $j_t$ with $t \in \{x,...,T\}$ and with $h = true$ when we have a hired worker at disposition.
So the solution that we are looking for is $OPT(0, false)$.

The cost of a single task can be explained using two cases:

When $h = true$ we must take one of this two subcases, the one with the minimum cost:
\begin{itemize}
    \item We use the hired worker that we have to pay him $s$ for the task $j_t$;
    \item We fire him paying $S$ and then we use a freelance paying the cost $c_t$ for the task $j_t$;
\end{itemize}
On the contrary, with $h = false$, we must consider the subcase of the minimum cost from the following two:
\begin{itemize}
    \item We assume a hired work paying $C$ and then we pay $s$ for the task $j_t$;
    \item We use again a freelance paying the cost $c_t$ for the task $j_t$;
\end{itemize}

We have to not consider the case in which there is not a task at the time instant $t$ and instead we can simply set the cost $c_t$ of a freelance to $0$ in that case.
To prove this claim assume that we do not have a task $j_t$ at the instant $t$ (we call it a "no task" time instant) and we have a hired worker.
In this case, we must choose one of the following possibilities:
\begin{itemize}
    \item Fire the hired worker and wait until the next task;
    \item Pay him to do nothing;
\end{itemize}
Otherwise, when we do not have a hired worker we do nothing.

Now if we consider a freelance with cost $0$ we can express the cost of the "not task" as follows:

When $h = true$ we must take one of this two subcases, the one with the minimum cost:
\begin{itemize}
    \item We use the hired worker that we have to pay him $s$ for the "not task" $j_t$;
    \item We fire him paying $S$ and then we use a freelance paying 0 for the task $j_t$;
\end{itemize}
On the contrary, with $h = false$, we must consider the subcase of the minimum cost from the following two:
\begin{itemize}
    \item We assume a hired work paying $C$ and then we pay $s$ for the task $j_t$ (of course this can never be the minimum);
    \item We use again a freelance paying the cost 0 for the task $j_t$ (this is the always chosen option);
\end{itemize}

So considering a "not task" is equivalent of the previously described situation and we do not have to distinguish the cases in our algorithm, we just set $c_t = 0$ when there is not a task $j_t$.

Returning to $OPT(x, h)$, to the single cost of $j_t$ we must add the cost of the successive tasks until the time instant $T$, so we explore all the possible following cases:

\[
    OPT(x, h) = 
    \begin{cases}
        min(s + OPT(x+1, true), S + c_t + OPT(x+1, false)) & \text{if } h = true \\
        min(C + s + OPT(x+1, true), c_t + OPT(x+1, false)) & \text{if } h = false
    \end{cases}
\]

This can be traduced into an algorithm that explores all the possible configurations and so a brute-force. In order to gain a polynomial cost, we used the memorization of the results of $OPT(x, h)$.
We can store the solutions in a matrix $M_{T+1,2}$ storing in the first column the values of $OPT(x, false)$ and in the second $OPT(x, true)$. Obviously the rows are related to the $x$, so encoding $false = 0$ and $true = 1$ we can get the return value of $OPT(x, h)$ with $\big(\big(M\big)_x\big)_h$. Note that the last row of $M$ is present in order to avoid to check if we are in the case $t = T-1$.

The algorithm, \verb|min_cost|, is the following (tasks is an array of tuples (time instant, outsourcing cost), $T$ is a number and we must consider as input the time interval $I = \{0 ... T\}$):

\begin{pseudo}
algorithm $min\_cost\_aux(t, T, s, C, S, c, h, M)$
    if $t$ is $T$
        return $0$
    if $((M)_{t+1})_1$ is $empty$
         $((M)_{t+1})_1 = min\_cost\_aux(t+1, T, s, C, S, c, 1, M)$
    if $((M)_{t+1})_0$ is $empty$
         $((M)_{t+1})_0 = min\_cost\_aux(t+1, T, s, C, S, c, 0, M)$
    if $h$ is $1$
        return $min(s + ((M)_{t+1})_1, S + c_t + ((M)_{t+1})_0)$
    else if $h$ is $0$
        return $min(C + s + ((M)_{t+1})_1, c_t + ((M)_{t+1})_0)$
\end{pseudo}
\begin{pseudo}
algorithm $min\_cost(I, s, C, S, tasks)$
    $M :=$ new $Matrix(|I|+1, 2)$
    $c :=$ new $Array(|I|)$
    $c_i = 0$ $\forall i \in I$
    $j := 0$
    foreach $t \in I$
        while $j < |tasks| \land (tasks_j)_0$ is $t$
            $c_t = c_t + (tasks_j)_1$
            $j = j +1$
    return $min\_cost\_aux(0, |I|, s, C, S, c, 0, M)$
\end{pseudo}

The foreach loop in the \verb|min_cost| body costs $T$ plus the number of tasks that are not alone in an instant, generally depends on the size of the tasks array.

In general the execution of the body of \verb|min_cost_aux| takes $O(1)$ excluding the recursive calls that it generates. We can count the number of recursion counting the entries of $M$ that are not empty.

Every time the procedure invokes the recurrence it fills two entries of the matrix. An entry cannot be filled more than one time. The entries in $M$ are $2*T+2$ and so the it performs at most $2*T+2$ recursions and so the cost is linear, $O(T)$.

The final cost is so $O(|I| + |tasks|) = O(T + |tasks|)$.

The proof of correctness is the following:

In the base case $t = T-1$, we consider two options in order to choose the best worker:
\begin{itemize}
    \item $h = true$: the minimum cost is $min(s, S + c_t)$;
    \item $h = false$: the minimum cost is $min(C + s, c_t)$;
\end{itemize}

Now assume that \verb|min_cost| returns the minimum for $t+1$ when using a hired worker, $X$, and the minimum cost for $t+1$ when using a freelance, $Y$.

For the case $t$ we consider two options:
\begin{itemize}
    \item $h = true$: the minimum cost is $min(s + X, S + c_t + Y)$;
    \item $h = false$: the minimum cost is $min(C + s + X, c_t + Y)$;
\end{itemize}

So the minimum is always returned in every iteration.

\subsection*{Part 2}

We can apply the considerations about the "not tasks" and the multiple tasks in a time instant of the previous point also to this problem.

With a cost matrix $CM_{T,K}$ we define the individual cost of a freelance of skill $k \in \{0 ... K\}$ at time $t \in \{0 ... T\}$ as follows:

\bigskip
$((CM)_t)_k = \Sigma_{j \in J_{t,k}} cost(j)$ with $J_{t,k} = \{j | time(j) = t \land k \in skills(j)\}$
\bigskip

With this consideration we merged all the tasks at the same time in a single task with a different cost for each skill. 
This is possible due to the fact that if we have an hired worker with the skill $k$ at time $t$ he can process all the works at time $t$ that require the skill $k$.
So the choice is or use an hired worker for the skill $k$, or use all freelances with the skill $k$ for the tasks at time $t$.

With a similar consideration as the one of problem 4.1, we insert costs 0 in $((CM)_t)_k$ when all tasks at time $t$ do not require the skill $k$. If there are not tasks at time $t$ we insert a row of all zeroes.

Now there is only a task for time instant and all tasks have the same number of individual costs, $K$.

We can solve the problem using a brute-force that do a recursion over all possible permutation of hired and freelance worker at each time instant.
$h$ is an array of $K$ elements that associate the skill $k$ to a boolean representing if we have an hired worker with the skill $k$ or not.

\[
    helper(h, next, t) = \mathlarger{\sum}_{k \in \{0 ... K\}}
    \begin{cases}
        s & \text{if } h_k = true \land next_k = true \\
        S + ((CM)_t)_k & \text{if } h_k = true \land next_k = false \\
        C + s & \text{if } h_k = false \land next_k = true \\
        ((CM)_t)_k & \text{if } h_k = false \land next_k = false
    \end{cases}
\]

\[
    OPT(t, h) = min\Big\{ OPT(t+1, next) + helper(h, next, t)  \text{ }\forall\text{ } next \in D'_{(2,K)}({true, false})\Big\}
\]

The cost of this recurrence is $(2^K)^K*T$. 
We can memorize $OPT(t, next)$ in a matrix $M_{T,2^K}$ in order to gain a polynomial cost in function of $2^K$. The first dimension represents the time instants, the second the dispositions with repetitions in $D'_{(2,T)}({true, false})$ (always with $true=1$ and $false=0$).

In pseudocode (tasks is an array of tuples (time instant, outsourcing cost, has skill 1 ... has skill K) and $I = \{0 ... T\}$):

\begin{pseudo}
algorithm $skills\_min\_cost\_aux(t, T, s, C, S, CM, h, M, K, disps)$
    if $t$ is $T$
        return $0$
    $r := \{\}$
    for $i = 0$ to $2^K$
        if $((M)_{t+1})_i$ is $empty$
            $((M)_{t+1})_i = skills\_min\_cost\_aux(t+1, T, s, C, S, CM, disps_i, M, K)$
        $cost := ((M)_{t+1})_i$
        for $k = 0$ to $K$
            if $h_k = 1 \land (disps_i)_k = 1$
                $cost = cost + s$
            else if $h_k = 1 \land (disps_i)_k = 0$
                $cost = cost + S + ((CM)_t)_k$
            else if $h_k = 0 \land (disps_i)_k = 1$
                $cost = cost + C + s$
            else if $h_k = 0 \land (disps_i)_k = 0$
                $cost = cost + ((CM)_t)_k$
        $r = r \cup \{cost\}$
    return $min(r)$
\end{pseudo}

\begin{pseudo}
algorithm $skills\_min\_cost(I, s, C, S, K, tasks)$
    $M :=$ new $Matrix(|I|+1, 2^K)$
    $h := $ new $Array(K)$
    $CM :=$ new $Matrix(|I|, K)$
    $disps := dispositions\_with\_repetitions((true, false), K)$
    for $k = 0$ to $K$
        $h_k = 0$
        $j := 0$
        foreach $t \in I$
            $((CM)_t)_k = 0$
            while $j < |tasks| \land (tasks_j)_0$ is $t$
                if $(tasks_j)_{2+k}$ is $true$
                    $((CM)_t)_k = ((CM)_t)_k + (tasks_j)_1$
                $j = j +1$
    return $skills\_min\_cost\_aux(0, |I|, s, C, S, CM, h, M, K, disps)$
\end{pseudo}

The cost of the body of \verb|skills_min_cost| is $O(K*(|I|+|tasks|))$ (note that it is more or less $K$ time the loop in \verb|min_cost|).
The cost of the body of \verb|skills_min_cost_aux| is $O(2^K*K)$ if we do not consider the recurive calls because we have a loop of $K$ iterations in a loop of $2^K$ iteration. Not that the loop at line 9 can be avoided if we preprocess the value in a matrix.
In order to get the number of recursion of \verb|skills_min_cost_aux| we can count the number of entries that are filled in $M$ because an entry is filled only one time when a new call is performed.
The matrix size of $(|I|+1)*(2^K)$ so the total cost of \verb|skills_min_cost_aux| is $O(|I|*2^K*2^K*K) = O(|I|*2^\{2K\}*K)$.
The final cost is so $O(K*(|I|+|tasks|) + |I|*2^\{2K\}*K) = O(2^\{2K\}*K*T + K*T + K*|tasks|)$. With $L = 2^K$ it is $O(L^2*log_2(L)*T + log_2(L)*(T+|tasks|))$ that is polynomial.

To prove that the algorithm is correct we proceed by induction.

% TODO

\bigskip
\section*{Exercise 5}

The related code is in the Appendix.

\subsection*{Part 1}

Given a weighted graph $G(V, E)$, to decide if exists an MST containing an edge $e \in E$ we can exploit two properties.

The cycle property \cite{cicle_prop}:

\bigskip
{\em For any cycle C in the graph, if the weight of an edge e of C is larger than the individual weights of all other edges of C, then this edge cannot belong to an MST.} 
\bigskip

The cut property \cite{cut_prop}:

\bigskip
{\em For any cut C of the graph, if the weight of an edge e in the cut-set of C is strictly smaller than the weights of all other edges of the cut-set of C, then this edge belongs to all MSTs of the graph.} 
\bigskip

Without loss of generality, we can also assume that all weights in the graph are distinct because we can always differentiate two equal weighted edges adding a small constant $c$ to one of the weights without changing the result of the Kruskal algorithm.

The idea is to determinate if starting from one endpoint of $e$ ($v$) we can reach the other ($u$) considering only the edges with weights lower than the weight of $e$ ($w$).
We call the graph with only these edges $G'(V', E')$.
If that happens, we have a connected component that contains both $v$ and $u$ and so adding $e$ to such subgraph we obtain a cycle in which $e$ is the edge with the maximum weight. This violates the cycle property, so $e$ does not belong to any MST.
In the other case, when $v$ and $u$ are not connected with edges with weight less than $w$, if exists a set $S$ for which $v \in S \land u \in V' \setminus S$ the cut property implies that $e$ is in all MSTs.
We choose $S$ as all nodes that can be reached by $v$ in $G'$ so that cannot exists an edge with weight less than $w$ and one endpoint in $S$ and the other in $V' \setminus S$. If such edge exists, the endpoint in $V' \setminus S$ is reachable from $v$ so it is a contradiction.
This implies that $e$ is the edge with minimum cost with an endpoint in $S$ and the other in $V' \setminus S$, so $e$ belongs to all MSTs.

We designed an algorithm, \verb|edge_is_in_mst|, based on DFS in order to verify if exists a path formed by edges with weight less than $w$ that connects $v$ to $u$:

\begin{pseudo}
algorithm $edge\_is\_in\_mst\_aux(G, e, v)$
    $r := true$
    $v.visited = true$
    foreach $i \in G.neighbors(v)$
        if $G.weight(v, i) >= G.weight(e)$
            skip
        if $i$ is $e.u$
            return $false$
        if not $i.visited$
            $r = r and edge\_is\_in\_mst\_aux(G, e, i)$
    return $r$
\end{pseudo}
\begin{pseudo}
algorithm $edge\_is\_in\_mst(G, e)$
    return $edge\_is\_in\_mst\_aux(G, e, e.v)$
\end{pseudo}

Checking the weight of adjacent edges does not add cost to the DFS since is a $O(1)$ operation. Also stopping the algorithm when \verb|e.u| is encountered does not add any cost, so the final cost of \verb|edge_is_in_mst| is the cost of a DFS, $O(|V|+|E|)$.

\subsection*{Part 2}

Given a weighted graph $G(V, E)$, to compute an MST that contains a determinate edge $e$ we designed an algorithm based on Kruskal with a sorted list as a source of edges.
This Kruskal version has a cost of $O(|E|log|E|)$ because it uses a sorting algorithm based on comparison \footnote{In the implementation we used the standard python sort function that is based on Timsort \cite{timsort}}. The action of removing the edges with the minimum weight is done in constant time.

Our algorithm is the following:

\begin{enumerate}
    \item check if $e$ can be in a MST using \verb|edge_is_in_mst|, if not exit with an error;
    \item sort the edges using the weights and store them in a list $l$;
    \item extract the edge $e$ from $l$;
    \item add $e$ to the MST;
    \item continue with the itarations of Kruskal using $l$ as source of edges;
\end{enumerate}

In pseudocode:

\begin{pseudo}
algorithm $mst\_from\_edge(G, e)$
    if not $edge\_is\_in\_mst(G, e)$
        error()
    foreach $v \in G.V$
        $make\_set(v)$
    $ordered := sort\_by\_increasing\_weigth(G.E)$
    $ordered = ordered \setminus e$
    $mst := \{e\}$
    foreach $o \in ordered$
        if $find\_set(o.v)$ is not $find\_set(o.u)$
            $mst = mst \cup \{o\}$
            $union(o.v, o.u)$
    return $mst$
\end{pseudo}

The action 1 costs $O(|V|+|E|)$ as described before.
The action 2, the sorting, costs $O(|E|log|E|)$.
Action 3 and 4 are in constant time.
So the exact cost of \verb|mst_from_edge| is $O(|V|+|E| + |E|log|E|)$.
With the assumption of $|E| > |V|$ (true if $G$ is connected)  our algorithm cost is $O(|E|log|E|)$.

To prove the corretness of \verb|mst_from_edge| we assume that the cut property is verified for $e$ (\verb|edge_is_in_mst| check for this).

The output $Y$ is a spanning tree because:
\begin{itemize}
    \item cannot have a cycle thanks to the check in the algorithm;
    \item all nodes of $G$ belongs to $Y$;
    \item cannot be disconnected, since the first encountered edge that joins two components of $Y$ would have been added;
\end{itemize}

For the minimality we proceed by induction proving the proposition $P$:

\bigskip
{\em If F is the set of edges chosen at any stage of the algorithm, then there is some minimum spanning tree that contains F.}
\bigskip

\begin{itemize}
    \item At the beginning, when $F = \{e\}$, $P$ is correct thanks to the cut property.
    \item Assume $p$ is true for some set $F$ and $T$ be the MST that contains $F$:
    \begin{itemize}
        \item after choosing the next edge $g$, if $g$ is in $T$ then $P$ is verified for $F \cup \{g\}$;
        \item else if $g$ is not in $T$ then $T \cup \{g\}$ has a cycle $C$ and there is an edge $f$ that belongs to $C$ and $T$ but not to $F$. Then $T \setminus \{f\} \cup \{g\}$ is a tree with weigth $\leq$ of the weigth of $T$ because the weigth of $f$ cannot be $<$ of the weigth of $g$ (or the algorithm would have chosen $f$ and not $g$). $P$ is verified for $T \setminus \{f\} \cup \{g\}$ that is a MST that contains $F \cup \{g\}$; 
    \end{itemize}
    \item by induction $P$ holds also when $F$ is a spanning tree (when $Y$ is $F$) and so it is a MST.
\end{itemize}

We proved that $Y$ is a spanning tree, that is minimum and that contains $e$.

\newpage

\section*{Appendix}

\subsection*{Exercise 4 Code}

\begin{ccode}
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define AT(mat, x, y) (mat)[(x)*2 + (y)]
#define MIN(a, b) ((a) <= (b) ? (a) : (b))

#define HIRED 1
#define FREELANCE 0

struct Task
{
    int time;
    int cost;
};

int min_cost_aux(int last_worker_type, int t, int T, int s, int C, int S, int* c, int* matrix)
{
  if(t == T)
    return 0;
  
  if(AT(matrix, t+1, HIRED) == -1)
    AT(matrix, t+1, HIRED) = min_cost_aux(HIRED, t+1, T, s, C, S, c, matrix);
  if(AT(matrix, t+1, FREELANCE) == -1)
    AT(matrix, t+1, FREELANCE) = min_cost_aux(FREELANCE, t+1, T, s, C, S, c, matrix);
  
  int x,y;
  if(last_worker_type == HIRED) {
    x = s + AT(matrix, t+1, HIRED);
    y = S + c[t] + AT(matrix, t+1, FREELANCE);
  }
  else {
    x = C + s + AT(matrix, t+1, HIRED);
    y = c[t] + AT(matrix, t+1, FREELANCE);
  }
  
  return MIN(x, y);
}


int min_cost(int T, int s, int C, int S, struct Task* tasks, int task_num)
{
    int* matrix = calloc(sizeof(int), (2*T +2));
    memset(matrix, -1, sizeof(int)*2*T);
    
    int* c = calloc(sizeof(struct Task), T);
    int i, j;
    for(i = 0, j = 0; i < T; ++i) {
        while(j < task_num && tasks[j].time == i) {
            c[i] += tasks[j].cost;
            ++j;
        }
    }
    
    int r = min_cost_aux(FREELANCE, 0, T, s, C, S, c, matrix);
    
    free(matrix);
    free(c);
    return r;
}

int main()
{
    struct Task tasks[] = {{0,3},{0,2},{1,6},{4,1}};
    int sol = min_cost(5, 2, 2, 3, tasks, 4);
    
    printf("%d\n", sol); //10
    return 0;
}
\end{ccode}

\newpage

\subsection*{Exercise 5 Code}

\begin{pycode}
import networkx as nx

def is_in_mst(G, e):
    visited = [False]*(len(G.nodes())) 
    e_w = G.edges[e]["weight"]
    
    def aux(v):
        visited[v] = True
        r = True
        
        for i in G.neighbors(v):
            if G.edges()[v,i]["weight"] >= e_w:
                continue
            if i == e[1]:
                return False
            if visited[i] == False: 
                r = r and aux(i)
        
        return r
    
    return aux(e[0])


def kruskal(G, e=None): 
    # e!=None forces to include edge e in the MST
    # otherwise standard kruskal is performed
    
    def find(parent, i):
        if parent[i] == i:
            return i
        return find(parent, parent[i])

    def union(parent, order, x, y):
        rx = find(parent, x)
        ry = find(parent, y)
        if order[rx] < order[ry]:
            parent[rx] = ry
        elif order[rx] > order[ry]:
            parent[ry] = rx
        else :
            parent[ry] = rx
            order[rx] += 1

    mst = []
    
    i = 0
    j = 0
    
    s_edges = sorted(G.edges(), key=lambda x: G.edges[x]['weight'])
    if e is not None:
        s_edges.remove(e)
        s_edges = [e] + s_edges
        
    parent = []
    rank = [] 

    for n in G.nodes(): 
        parent.append(n)
        rank.append(0)
  
    while j < len(G.nodes())-1: 
        if i == len(s_edges): break
        
        u,v = s_edges[i]
        w = G.edges[u,v]['weight']
        
        i += 1
        x = find(parent, u)
        y = find(parent, v)

        if x != y: 
            j += 1 
            mst.append((u,v,w))
            union(parent, rank, x, y)
    
    return mst
    
def mst_from_edge(G, e):
    if not is_in_mst(G, e):
        raise Exception("edge %s cannot be in a MST" % str(e))
    return kruskal(G, e)
    
\end{pycode}

\newpage
\subsection*{4.2 solution running K times 4.1}

\begin{pseudo}
algorithm $skills\_min\_cost2(I, s, C, S, K, tasks)$
    $r := 0$
    for $k = 0$ to $K$
        $c :=$ new $Array(|I|)$
        $j := 0$
        foreach $t \in I$
            $c_t = 0$
            while $j < |tasks| \land (tasks_j)_0$ is $t$
                if $(tasks_j)_{2+k}$ is $true$
                    $c_t = c_t + (tasks_j)_1$
                $j = j +1$
        $M :=$ new $Matrix(|I|+1, 2)$
        $r = r + min\_cost\_aux(0, |I|, s, C, S, c, 0, M)$
    return $r$
\end{pseudo}

The cost of the body of the loop at line 3 is $O(|I|+|tasks|)$ whithout considering the call to \verb|min_cost_aux|.
The cost of \verb|min_cost_aux| is $O(|I|)$ as shown in 4.1.
This implies that the total cost of \verb|skills_min_cost2| is $K$ times the cost of the loop at line 3, $O(K*(2*|I|+|tasks|))$

Can this formulation of the algorithm be correct? I would like to discuss few minutes about this question during the oral exam.

\vfill
\bibliography{main} 
\bibliographystyle{ieeetr}

\end{document}
